# Comment Toxicity Detection

This project detects toxic comments using a deep learning model and provides real-time predictions through a Streamlit web application.

## Features
- Multi-label toxicity classification
- Deep learning model using LSTM
- Real-time predictions
- Simple and interactive Streamlit UI

## Toxicity Categories
- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

## Technologies Used
- Python
- TensorFlow / Keras
- Pandas, NumPy
- Streamlit
- Git & GitHub

## Project Structure

comment-toxicity-detection/
│
├── app.py
├── data/
│ ├── train.csv
│ └── test.csv
├── src/
│ ├── preprocessing.py
│ └── model.py
├── saved_models/
│ └── toxicity_model.keras
├── notebooks/
├── requirements.txt
└── README.md


## How to Run the Project

### Step 1: Install Dependencies


### Step 2: Run Streamlit App

### Step 3: Enter a Comment
Type any comment in the input box to see toxicity predictions.

## Sample Output
The app displays probability scores for each toxicity category.

## Author
**Sakthi**

## GitHub Repository
https://github.com/Sakthi-luffy/comment-toxicity-detection

